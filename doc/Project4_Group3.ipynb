{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g1YWiD2WA1fN"
   },
   "source": [
    "# Optical character recognition (OCR) \n",
    "Project 4 Group 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rViGVJ0xRK5u"
   },
   "source": [
    "## Error Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a0c7XybVBJrI"
   },
   "source": [
    "First of all, we need to detect errors, or incorrectly processed words. Here we extract features according to the paper and use SVM for garbage detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwpNpdFxUqll"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import itertools\n",
    "#import itertools\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "gw4gIzwQRDqJ",
    "outputId": "3616cd5c-2bfd-40c3-f14d-181a99982a77"
   },
   "outputs": [],
   "source": [
    "##### read ground_truth\n",
    "ground_dir = glob.glob(os.path.join(os.getcwd(),'../data/ground_truth','*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zoq2wOeFRDqQ"
   },
   "outputs": [],
   "source": [
    "# make sure corresponding files have the same number of lines\n",
    "tess_dir = glob.glob(os.path.join(os.getcwd(),'../data/tesseract','*.txt'))\n",
    "file_name_gd = []\n",
    "file_name_td = []\n",
    "for gd, td in zip(ground_dir, tess_dir):\n",
    "        with open(gd, encoding=\"utf8\") as ground_file:    #, encoding=\"utf8\"\n",
    "            with open(td, encoding=\"utf8\") as tess_file:                \n",
    "                ground_r = list(ground_file.readlines()) \n",
    "                tess_r = list(tess_file.readlines())\n",
    "                if len(tess_r) == len(ground_r):\n",
    "                    file_name_td.append(td)\n",
    "                    file_name_gd.append(gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rz5JErxMRDqU"
   },
   "outputs": [],
   "source": [
    "# make sure all the lines have the same size.\n",
    "# recreate ground_tokens and tess_tokens\n",
    "ground_tokens=[]\n",
    "tess_tokens=[]\n",
    "for gd, td in zip(file_name_gd, file_name_td):\n",
    "        with open(gd) as file1:\n",
    "            with open(td) as file2:\n",
    "                for line1,line2 in zip(file1,file2):\n",
    "                    if len(line1)==len(line2):\n",
    "                        #if length is different, skip that line\n",
    "                        for word1,word2 in zip(line1.split(),line2.split()):\n",
    "                            ground_tokens.append(word1)\n",
    "                            tess_tokens.append(word2)\n",
    "#ground_tokens and tess_tokens are a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "xs2RfLUgXj6e",
    "outputId": "c4ace6b0-a38d-42a0-c5fe-0c412f0176eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['communlcatlons', 'network.', 'Member', 'companles', 'are', 'strongly', 'encouraged', 'to', 'provlde', 'thls', 'needed', 'support.', 'The', 'state', 'advocacy', 'program\"', '1nclud1ng', 'the', 'new', 'CMA/LINC', 'computer', 'network.', 'will', 'be', 'heavlly', '1nvolved', '1n', '1995', '1n', 'the']\n",
      "['communications', 'network.', 'Member', 'companies', 'are', 'strongly', 'encouraged', 'to', 'provide', 'this', 'needed', 'support.', 'The', 'state', 'advocacy', 'program*', 'including', 'the', 'new', 'CMA/LINC', 'computer', 'network,', 'will', 'be', 'heavily', 'involved', 'in', '1986', 'in', 'the']\n"
     ]
    }
   ],
   "source": [
    "print(tess_tokens[:30])\n",
    "print(ground_tokens[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "IYwWhSBlRDqX",
    "outputId": "41f1bf1d-aad9-42e4-8b37-daaf9e123d8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152143\n",
      "152143\n"
     ]
    }
   ],
   "source": [
    "print(len(tess_tokens))\n",
    "print(len(ground_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PbgdRcXPRDqc"
   },
   "outputs": [],
   "source": [
    "# for every word in tess_tokens, y indicates the correctness of the word\n",
    "y = []\n",
    "for gt, tt in zip(ground_tokens, tess_tokens):\n",
    "        if gt == tt:\n",
    "            y.append(0)   # 0 indicates correct\n",
    "        else:\n",
    "            y.append(1)   # 1 indicates error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uIxhIzlfUw7r"
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(tess_tokens)   \n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "ground_train = [ground_tokens[i] for i in X_train.index.tolist()]\n",
    "ground_test = [ground_tokens[i] for i in X_test.index.tolist()]\n",
    "X_train = X_train[0].tolist()\n",
    "X_test = X_test[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "e6hxAoaAmSXD",
    "outputId": "5fa0fbc0-a836-4cea-e349-e9a31bd23eef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hundreds.', 'chemlcal', 'total', 'an', 'recalled', 'chemlcal', 'young', '1992793.', 'to', 'technlcal', 'have', 'products.', '1:', 'been', '(except', 'be', 'change', 'testlng', 'prlorlty', 'h.d', 'from', 'them', 'Vinyl', 'out', 'the', 'a.', 'organlzatlon', 'Forum', 'carry', 'antltrust']\n",
      "['hundreds,', 'chemical', 'total', 'an', 'recalled', 'chemical', 'young', '1982-83.', 'to', 'technical', 'have', 'products.', 'it', 'been', '(except', 'be', 'change', 'testing', 'priority', 'had', 'from', 'them', 'vinyl', 'out', 'the', 'H.', 'organization', 'Forum', 'carry', 'antitrust']\n",
      "[1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:30])\n",
    "print(ground_train[:30])\n",
    "print(y_train[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W4xL-rP0tgm_"
   },
   "outputs": [],
   "source": [
    "# define character type\n",
    "vowels = list('aeiou')\n",
    "consonants = list(\"bcdfghjklmnpqrstvwxyz\")\n",
    "digits = list('0123456789')\n",
    "\n",
    "# Rule 9: If the word contains the # of upper case characters > # of lower case character => garbadge\n",
    "# count # of upper case characters \n",
    "def count_up(word):\n",
    "    upper = [c for c in word if c.isupper()]\n",
    "    return len(upper)\n",
    "# count # of lower case characters\n",
    "def count_low(word):\n",
    "    lower = [c for c in word if c.islower()]\n",
    "    return len(lower)\n",
    "# Rule 8: If the string contains at least 3 consecutive of same symbol => garbadge \n",
    "# count # consecutive occurrences of the same symbol\n",
    "def count_cons_occur_symbol(word): \n",
    "    count = 0 \n",
    "    tmp = 0 \n",
    "    curr = ''\n",
    "    for c in word:\n",
    "        if curr==c:\n",
    "            tmp +=1\n",
    "        else:\n",
    "            count = max(tmp,count)\n",
    "            tmp = 1 \n",
    "            curr = c\n",
    "    count = max(tmp, count)            \n",
    "    return count \n",
    "   \n",
    "# Rule 11: if the word contains 4 consecutive vowels or 5 consecutive consonants => garbage\n",
    "#consecutive occurrences of the same consonants\n",
    "def count_cons_occur_consonants(word):  \n",
    "    max_count=0\n",
    "    count = 0\n",
    "    curr = ''\n",
    "    for c in word:\n",
    "        if c in consonants:\n",
    "            if curr == c:\n",
    "                count += 1\n",
    "            else:\n",
    "                max_count = max(max_count, count)\n",
    "                curr = c\n",
    "                count = 1\n",
    "    max_count = max(max_count, count)\n",
    "    return(max_count)\n",
    "\n",
    "#extract a subset of word\n",
    "def trim_word(word, start=1, end=1):\n",
    "    return word[start:len(word) - end]\n",
    "\n",
    "            \n",
    "def safe_div(x,y):\n",
    "    if y == 0:\n",
    "        return 0\n",
    "    return x / y\n",
    "\n",
    "\n",
    "def get_bigram_freq(word, bi_dict):\n",
    "    word = word.lower()\n",
    "    bf = []\n",
    "    for i in range(len(word)-1):\n",
    "        key = word[i:i+2]\n",
    "        bf.append(bi_dict[key])\n",
    "    return(bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zd39iCOdEfom",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### find LB in ground_truth, prepared for bigram features\n",
    "# ground_tokens of all words in lowercase\n",
    "lower_ground_tokens = []\n",
    "for tk in ground_tokens:\n",
    "    tkl_g = tk.lower()\n",
    "    lower_ground_tokens.append(tkl_g)\n",
    "\n",
    "# A dict of all bigram frequencies\n",
    "bigram_dict = collections.defaultdict(int)\n",
    "for tk_g in lower_ground_tokens:\n",
    "    for i in range(len(tk_g)-1):\n",
    "        key = tk_g[i:i+2]\n",
    "        bigram_dict[key] += 1\n",
    "#bigram_dict is a dictionary of bigram frequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'co': 7987,\n",
       "             'om': 4529,\n",
       "             'mm': 2163,\n",
       "             'mu': 645,\n",
       "             'un': 2570,\n",
       "             'ni': 2774,\n",
       "             'ic': 5599,\n",
       "             'ca': 4529,\n",
       "             'at': 12092,\n",
       "             'ti': 12863,\n",
       "             'io': 8332,\n",
       "             'on': 15058,\n",
       "             'ns': 4286,\n",
       "             'ne': 3808,\n",
       "             'et': 2546,\n",
       "             'tw': 328,\n",
       "             'wo': 1168,\n",
       "             'or': 8733,\n",
       "             'rk': 693,\n",
       "             'k.': 41,\n",
       "             'me': 5973,\n",
       "             'em': 4018,\n",
       "             'mb': 941,\n",
       "             'be': 3693,\n",
       "             'er': 10941,\n",
       "             'mp': 2223,\n",
       "             'pa': 3439,\n",
       "             'an': 12007,\n",
       "             'ie': 2439,\n",
       "             'es': 9802,\n",
       "             'ar': 6346,\n",
       "             're': 13219,\n",
       "             'st': 7403,\n",
       "             'tr': 3531,\n",
       "             'ro': 6615,\n",
       "             'ng': 5832,\n",
       "             'gl': 97,\n",
       "             'ly': 1988,\n",
       "             'en': 10468,\n",
       "             'nc': 2951,\n",
       "             'ou': 4676,\n",
       "             'ur': 3018,\n",
       "             'ra': 4903,\n",
       "             'ag': 1376,\n",
       "             'ge': 2240,\n",
       "             'ed': 7693,\n",
       "             'to': 5970,\n",
       "             'pr': 5469,\n",
       "             'ov': 1596,\n",
       "             'vi': 2345,\n",
       "             'id': 1768,\n",
       "             'de': 5418,\n",
       "             'th': 16347,\n",
       "             'hi': 2460,\n",
       "             'is': 6582,\n",
       "             'ee': 3202,\n",
       "             'su': 3112,\n",
       "             'up': 1452,\n",
       "             'pp': 1169,\n",
       "             'po': 4077,\n",
       "             'rt': 2942,\n",
       "             't.': 520,\n",
       "             'he': 14311,\n",
       "             'ta': 5288,\n",
       "             'te': 9782,\n",
       "             'ad': 2666,\n",
       "             'dv': 332,\n",
       "             'vo': 525,\n",
       "             'oc': 1636,\n",
       "             'ac': 3132,\n",
       "             'cy': 740,\n",
       "             'og': 1190,\n",
       "             'gr': 2367,\n",
       "             'am': 1770,\n",
       "             'm*': 5,\n",
       "             'in': 14567,\n",
       "             'cl': 915,\n",
       "             'lu': 861,\n",
       "             'ud': 831,\n",
       "             'di': 3077,\n",
       "             'ew': 891,\n",
       "             'cm': 908,\n",
       "             'ma': 3695,\n",
       "             'a/': 16,\n",
       "             '/l': 8,\n",
       "             'li': 3521,\n",
       "             'pu': 668,\n",
       "             'ut': 1841,\n",
       "             'k,': 54,\n",
       "             'wi': 1952,\n",
       "             'il': 2881,\n",
       "             'll': 3214,\n",
       "             'ea': 3764,\n",
       "             'av': 880,\n",
       "             'nv': 701,\n",
       "             'ol': 2000,\n",
       "             'lv': 209,\n",
       "             've': 5543,\n",
       "             '19': 964,\n",
       "             '98': 710,\n",
       "             '86': 198,\n",
       "             'cr': 778,\n",
       "             'ri': 3975,\n",
       "             'it': 6795,\n",
       "             'al': 8282,\n",
       "             'ir': 1934,\n",
       "             'nm': 658,\n",
       "             'nt': 8147,\n",
       "             'ss': 3599,\n",
       "             'ue': 1441,\n",
       "             'if': 1057,\n",
       "             'fi': 1770,\n",
       "             'by': 1026,\n",
       "             'na': 3403,\n",
       "             'nf': 386,\n",
       "             'fe': 1617,\n",
       "             'ce': 3851,\n",
       "             'of': 5731,\n",
       "             'le': 4288,\n",
       "             'eg': 1695,\n",
       "             'gi': 1072,\n",
       "             'sl': 637,\n",
       "             'la': 3535,\n",
       "             'rs': 2309,\n",
       "             's,': 1342,\n",
       "             'el': 3045,\n",
       "             'y,': 462,\n",
       "             'nd': 8867,\n",
       "             'dw': 155,\n",
       "             'wa': 1621,\n",
       "             'sp': 1532,\n",
       "             'os': 2264,\n",
       "             'sa': 1279,\n",
       "             'ha': 4804,\n",
       "             'az': 416,\n",
       "             'za': 649,\n",
       "             'rd': 1436,\n",
       "             'do': 922,\n",
       "             'us': 3107,\n",
       "             'as': 5419,\n",
       "             's.': 2482,\n",
       "             'se': 6116,\n",
       "             'e,': 711,\n",
       "             'ot': 1871,\n",
       "             'e/': 27,\n",
       "             '/g': 5,\n",
       "             'sk': 496,\n",
       "             'p.': 94,\n",
       "             'ig': 1057,\n",
       "             'gh': 728,\n",
       "             'ht': 396,\n",
       "             't-': 100,\n",
       "             '-t': 121,\n",
       "             'o-': 108,\n",
       "             '-k': 41,\n",
       "             'kn': 108,\n",
       "             'no': 1610,\n",
       "             'ow': 1010,\n",
       "             'ct': 4186,\n",
       "             'nu': 968,\n",
       "             'ev': 1795,\n",
       "             'ex': 1701,\n",
       "             'xp': 660,\n",
       "             'sc': 804,\n",
       "             'op': 1976,\n",
       "             'pe': 2818,\n",
       "             'e.': 910,\n",
       "             'je': 302,\n",
       "             'ey': 534,\n",
       "             \"y'\": 124,\n",
       "             \"'s\": 916,\n",
       "             '\"t': 36,\n",
       "             'ox': 361,\n",
       "             'xi': 543,\n",
       "             'ph': 318,\n",
       "             't\"': 16,\n",
       "             '\",': 24,\n",
       "             'si': 3530,\n",
       "             'gn': 474,\n",
       "             'rl': 341,\n",
       "             'ja': 207,\n",
       "             'ua': 911,\n",
       "             'ry': 2032,\n",
       "             'nl': 178,\n",
       "             'eq': 578,\n",
       "             'qu': 887,\n",
       "             'ui': 647,\n",
       "             'ep': 2059,\n",
       "             'fo': 3282,\n",
       "             'rm': 688,\n",
       "             'rn': 1098,\n",
       "             'du': 2177,\n",
       "             'bu': 698,\n",
       "             'ls': 1140,\n",
       "             'so': 1887,\n",
       "             'lo': 1911,\n",
       "             'ws': 239,\n",
       "             'uc': 1185,\n",
       "             'ai': 1585,\n",
       "             'ec': 4053,\n",
       "             'mo': 1324,\n",
       "             'im': 1566,\n",
       "             'sh': 1230,\n",
       "             \"a'\": 292,\n",
       "             'af': 849,\n",
       "             'ff': 1283,\n",
       "             'fa': 625,\n",
       "             'iv': 2393,\n",
       "             'ci': 2150,\n",
       "             'ip': 618,\n",
       "             'pm': 313,\n",
       "             'cs': 169,\n",
       "             'y.': 557,\n",
       "             'w,': 42,\n",
       "             'ap': 989,\n",
       "             'pi': 396,\n",
       "             'dl': 144,\n",
       "             'ia': 2208,\n",
       "             'ab': 1152,\n",
       "             'bi': 776,\n",
       "             'ty': 1372,\n",
       "             'ef': 1231,\n",
       "             'm.': 239,\n",
       "             'rg': 922,\n",
       "             'oa': 602,\n",
       "             'au': 578,\n",
       "             'xc': 123,\n",
       "             'ch': 3814,\n",
       "             'l.': 243,\n",
       "             'n,': 594,\n",
       "             'ub': 1060,\n",
       "             'bl': 1388,\n",
       "             'hr': 331,\n",
       "             'lt': 848,\n",
       "             'bj': 157,\n",
       "             'nn': 504,\n",
       "             'bh': 27,\n",
       "             'ho': 1817,\n",
       "             'd,': 356,\n",
       "             'pt': 546,\n",
       "             'ys': 376,\n",
       "             'i2': 2,\n",
       "             '2a': 2,\n",
       "             'rf': 263,\n",
       "             'fu': 847,\n",
       "             'ob': 589,\n",
       "             'ba': 599,\n",
       "             'ga': 922,\n",
       "             'tt': 1992,\n",
       "             'ts': 2908,\n",
       "             'ru': 592,\n",
       "             'dg': 191,\n",
       "             '85': 153,\n",
       "             'mi': 3916,\n",
       "             '84': 96,\n",
       "             'cc': 505,\n",
       "             'ye': 640,\n",
       "             'nq': 12,\n",
       "             'cu': 1117,\n",
       "             'gu': 906,\n",
       "             'ul': 2432,\n",
       "             'aw': 356,\n",
       "             'w.': 105,\n",
       "             'a,': 178,\n",
       "             'tu': 1227,\n",
       "             '.v': 6,\n",
       "             'v.': 22,\n",
       "             'sw': 47,\n",
       "             'we': 1472,\n",
       "             '\"c': 49,\n",
       "             'e?': 4,\n",
       "             '?\"': 5,\n",
       "             '\"a': 43,\n",
       "             'e\"': 44,\n",
       "             'ei': 697,\n",
       "             'fr': 650,\n",
       "             'xa': 177,\n",
       "             'oi': 376,\n",
       "             'oh': 110,\n",
       "             'sy': 206,\n",
       "             'yl': 251,\n",
       "             'va': 727,\n",
       "             'n.': 622,\n",
       "             'c\"': 3,\n",
       "             ',\"': 18,\n",
       "             'ke': 897,\n",
       "             'l/': 5,\n",
       "             '/a': 13,\n",
       "             'br': 357,\n",
       "             'ax': 551,\n",
       "             'rr': 499,\n",
       "             'dd': 409,\n",
       "             'wh': 1054,\n",
       "             'tl': 480,\n",
       "             'da': 1258,\n",
       "             'dm': 378,\n",
       "             'ju': 294,\n",
       "             'hu': 120,\n",
       "             'xe': 308,\n",
       "             'ik': 120,\n",
       "             'ay': 792,\n",
       "             'rv': 385,\n",
       "             'rc': 912,\n",
       "             'nk': 149,\n",
       "             'bt': 74,\n",
       "             'ld': 1066,\n",
       "             '20': 122,\n",
       "             '00': 545,\n",
       "             'lk': 46,\n",
       "             'gy': 384,\n",
       "             '43': 23,\n",
       "             '36': 41,\n",
       "             '6)': 8,\n",
       "             'od': 859,\n",
       "             'r.': 646,\n",
       "             'pl': 1384,\n",
       "             'bs': 354,\n",
       "             'ck': 365,\n",
       "             'sm': 245,\n",
       "             '$6': 11,\n",
       "             '66': 24,\n",
       "             '60': 75,\n",
       "             'r,': 352,\n",
       "             'ib': 649,\n",
       "             '(s': 43,\n",
       "             'd)': 11,\n",
       "             'h.': 162,\n",
       "             '.r': 60,\n",
       "             '05': 18,\n",
       "             '26': 48,\n",
       "             '6,': 82,\n",
       "             'iz': 503,\n",
       "             'ez': 20,\n",
       "             'zi': 60,\n",
       "             'ds': 525,\n",
       "             'd-': 67,\n",
       "             '-b': 52,\n",
       "             'uf': 193,\n",
       "             'ka': 125,\n",
       "             'ks': 221,\n",
       "             'wl': 30,\n",
       "             \"e'\": 111,\n",
       "             '$2': 29,\n",
       "             's3': 1,\n",
       "             '3.': 62,\n",
       "             '.1': 20,\n",
       "             'x,': 25,\n",
       "             'i.': 44,\n",
       "             '.6': 12,\n",
       "             'ze': 347,\n",
       "             'ft': 256,\n",
       "             'd.': 547,\n",
       "             'aj': 187,\n",
       "             'jo': 389,\n",
       "             'l,': 221,\n",
       "             'go': 744,\n",
       "             'dj': 39,\n",
       "             '0,': 165,\n",
       "             '13': 65,\n",
       "             '$1': 69,\n",
       "             '10': 211,\n",
       "             'ko': 34,\n",
       "             'ki': 268,\n",
       "             'x.': 20,\n",
       "             'um': 640,\n",
       "             '6.': 76,\n",
       "             'mc': 305,\n",
       "             \"c'\": 66,\n",
       "             'bm': 114,\n",
       "             'fl': 278,\n",
       "             'ps': 286,\n",
       "             'a.': 282,\n",
       "             't,': 394,\n",
       "             'wn': 149,\n",
       "             'yt': 28,\n",
       "             'e:': 62,\n",
       "             '(1': 29,\n",
       "             '1)': 36,\n",
       "             'hn': 279,\n",
       "             's;': 127,\n",
       "             '(2': 25,\n",
       "             '2)': 39,\n",
       "             'rp': 282,\n",
       "             'yo': 232,\n",
       "             \"n'\": 130,\n",
       "             'gs': 306,\n",
       "             'gt': 105,\n",
       "             's:': 94,\n",
       "             '(w': 7,\n",
       "             '.)': 21,\n",
       "             '(m': 17,\n",
       "             's-': 32,\n",
       "             '-h': 22,\n",
       "             '33': 21,\n",
       "             '70': 90,\n",
       "             'xt': 239,\n",
       "             'tv': 13,\n",
       "             'sf': 74,\n",
       "             'g;': 8,\n",
       "             '40': 76,\n",
       "             '6%': 2,\n",
       "             '75': 54,\n",
       "             '5%': 9,\n",
       "             '%.': 9,\n",
       "             '1.': 100,\n",
       "             '.9': 6,\n",
       "             '4.': 52,\n",
       "             '.5': 28,\n",
       "             'eo': 182,\n",
       "             'tm': 345,\n",
       "             'wr': 56,\n",
       "             'oo': 579,\n",
       "             'eb': 125,\n",
       "             'ms': 525,\n",
       "             'lm': 73,\n",
       "             '11': 142,\n",
       "             'tf': 19,\n",
       "             '(r': 17,\n",
       "             'a)': 62,\n",
       "             'ny': 692,\n",
       "             '\"h': 22,\n",
       "             'd\"': 16,\n",
       "             '35': 44,\n",
       "             '50': 153,\n",
       "             '\"b': 10,\n",
       "             'y\"': 20,\n",
       "             'hy': 175,\n",
       "             '27': 51,\n",
       "             '7,': 74,\n",
       "             '5,': 94,\n",
       "             'g,': 150,\n",
       "             'd/': 26,\n",
       "             '/d': 11,\n",
       "             'bo': 813,\n",
       "             '3,': 75,\n",
       "             '5.': 59,\n",
       "             '28': 64,\n",
       "             '8,': 58,\n",
       "             'df': 23,\n",
       "             '81': 106,\n",
       "             '1-': 19,\n",
       "             '-1': 56,\n",
       "             'fy': 101,\n",
       "             'iq': 42,\n",
       "             'dk': 6,\n",
       "             'ug': 445,\n",
       "             '/o': 21,\n",
       "             'n-': 91,\n",
       "             '-s': 75,\n",
       "             'dr': 519,\n",
       "             'g-': 18,\n",
       "             's/': 31,\n",
       "             '/m': 13,\n",
       "             'nj': 73,\n",
       "             'oj': 65,\n",
       "             'gf': 8,\n",
       "             'eu': 106,\n",
       "             '-l': 17,\n",
       "             'p\"': 5,\n",
       "             'hd': 24,\n",
       "             'sd': 61,\n",
       "             '/c': 37,\n",
       "             '15': 82,\n",
       "             'yi': 108,\n",
       "             'e-': 124,\n",
       "             '-p': 45,\n",
       "             '25': 74,\n",
       "             '57': 13,\n",
       "             '76': 90,\n",
       "             'xm': 4,\n",
       "             'iu': 42,\n",
       "             'wt': 14,\n",
       "             'c.': 198,\n",
       "             'nz': 77,\n",
       "             '12': 128,\n",
       "             'n\"': 26,\n",
       "             'ak': 357,\n",
       "             '\"z': 2,\n",
       "             '-r': 37,\n",
       "             'fs': 58,\n",
       "             'g.': 203,\n",
       "             '(a': 51,\n",
       "             'fd': 21,\n",
       "             'yn': 27,\n",
       "             '(o': 14,\n",
       "             'cp': 28,\n",
       "             'f)': 3,\n",
       "             'hl': 191,\n",
       "             'g/': 12,\n",
       "             '30': 140,\n",
       "             '07': 25,\n",
       "             '7(': 1,\n",
       "             '87': 143,\n",
       "             '03': 313,\n",
       "             '38': 190,\n",
       "             '55': 22,\n",
       "             'mn': 76,\n",
       "             '7.': 62,\n",
       "             '2.': 73,\n",
       "             'lc': 56,\n",
       "             '.e': 10,\n",
       "             '.,': 47,\n",
       "             '18': 69,\n",
       "             '80': 81,\n",
       "             'h,': 73,\n",
       "             'nh': 40,\n",
       "             '14': 60,\n",
       "             '56': 16,\n",
       "             '\"n': 15,\n",
       "             'ek': 72,\n",
       "             '(z': 1,\n",
       "             'zh': 2,\n",
       "             'e)': 42,\n",
       "             'ok': 152,\n",
       "             'lr': 83,\n",
       "             'dy': 259,\n",
       "             '67': 21,\n",
       "             '.c': 12,\n",
       "             's)': 77,\n",
       "             '99': 33,\n",
       "             '9t': 8,\n",
       "             '8)': 8,\n",
       "             '0t': 9,\n",
       "             \"s'\": 71,\n",
       "             '.\"': 72,\n",
       "             '/n': 10,\n",
       "             '\"s': 38,\n",
       "             'h\"': 2,\n",
       "             '17': 50,\n",
       "             '59': 18,\n",
       "             'oe': 112,\n",
       "             '91': 23,\n",
       "             '93': 22,\n",
       "             'o.': 56,\n",
       "             '\"d': 11,\n",
       "             '16': 62,\n",
       "             'ii': 120,\n",
       "             '-a': 29,\n",
       "             'oz': 19,\n",
       "             'zo': 48,\n",
       "             'rb': 110,\n",
       "             'uo': 52,\n",
       "             'rw': 63,\n",
       "             'yr': 30,\n",
       "             '(d': 20,\n",
       "             '-w': 17,\n",
       "             'wv': 2,\n",
       "             'bc': 89,\n",
       "             'np': 61,\n",
       "             'eh': 131,\n",
       "             '-d': 57,\n",
       "             'p,': 41,\n",
       "             'pd': 24,\n",
       "             '\"i': 24,\n",
       "             's\"': 56,\n",
       "             '\".': 26,\n",
       "             'pg': 7,\n",
       "             'sr': 50,\n",
       "             '61': 33,\n",
       "             'ln': 41,\n",
       "             'l-': 39,\n",
       "             '-c': 61,\n",
       "             '-i': 15,\n",
       "             '90': 45,\n",
       "             '0%': 21,\n",
       "             'bb': 58,\n",
       "             'u.': 272,\n",
       "             '.s': 253,\n",
       "             'nr': 54,\n",
       "             'h-': 16,\n",
       "             '4,': 88,\n",
       "             '62': 32,\n",
       "             'lp': 71,\n",
       "             '-j': 7,\n",
       "             'f,': 32,\n",
       "             '(h': 15,\n",
       "             'hm': 75,\n",
       "             'mt': 45,\n",
       "             '21': 58,\n",
       "             '63': 30,\n",
       "             'gg': 69,\n",
       "             'n;': 33,\n",
       "             '22': 52,\n",
       "             \"d'\": 19,\n",
       "             'tc': 131,\n",
       "             '29': 40,\n",
       "             'b.': 47,\n",
       "             '),': 44,\n",
       "             './': 18,\n",
       "             '/p': 10,\n",
       "             '-f': 27,\n",
       "             '/b': 16,\n",
       "             \"l'\": 29,\n",
       "             'hs': 72,\n",
       "             '23': 37,\n",
       "             '65': 18,\n",
       "             'ae': 161,\n",
       "             '(n': 22,\n",
       "             'c)': 35,\n",
       "             \"r'\": 60,\n",
       "             '3%': 6,\n",
       "             '%;': 1,\n",
       "             '(8': 3,\n",
       "             '3)': 17,\n",
       "             ').': 72,\n",
       "             '1,': 177,\n",
       "             ',9': 15,\n",
       "             '94': 26,\n",
       "             '47': 22,\n",
       "             'r-': 45,\n",
       "             '83': 138,\n",
       "             'o,': 72,\n",
       "             '0:': 28,\n",
       "             ':0': 28,\n",
       "             '0-': 35,\n",
       "             ':4': 12,\n",
       "             '1:': 23,\n",
       "             ':2': 8,\n",
       "             '2:': 8,\n",
       "             'm)': 3,\n",
       "             '9:': 10,\n",
       "             '.m': 21,\n",
       "             'dq': 3,\n",
       "             '37': 209,\n",
       "             '79': 69,\n",
       "             '96': 44,\n",
       "             'ah': 33,\n",
       "             ':3': 9,\n",
       "             '5-': 31,\n",
       "             '45': 33,\n",
       "             'y-': 59,\n",
       "             'b,': 7,\n",
       "             '8:': 4,\n",
       "             'f.': 82,\n",
       "             'fm': 3,\n",
       "             'ym': 98,\n",
       "             'oy': 150,\n",
       "             'y:': 25,\n",
       "             'r:': 12,\n",
       "             'l:': 12,\n",
       "             'km': 12,\n",
       "             'n:': 29,\n",
       "             'xx': 17,\n",
       "             'xo': 16,\n",
       "             'jr': 24,\n",
       "             '68': 23,\n",
       "             'xh': 123,\n",
       "             '69': 29,\n",
       "             'n\\xad': 85,\n",
       "             '\"p': 22,\n",
       "             'r;': 6,\n",
       "             'lf': 115,\n",
       "             '82': 125,\n",
       "             '2,': 90,\n",
       "             'mr': 193,\n",
       "             't:': 28,\n",
       "             'y\\xad': 5,\n",
       "             '$9': 3,\n",
       "             '97': 209,\n",
       "             ',0': 112,\n",
       "             '0.': 63,\n",
       "             'e\\xad': 57,\n",
       "             '-6': 4,\n",
       "             'x\\xad': 6,\n",
       "             'd;': 24,\n",
       "             \"m'\": 6,\n",
       "             'p\\xad': 13,\n",
       "             'nw': 22,\n",
       "             'o:': 8,\n",
       "             'y;': 26,\n",
       "             '71': 47,\n",
       "             'm\\xad': 54,\n",
       "             'd:': 67,\n",
       "             '31': 82,\n",
       "             '3-': 17,\n",
       "             '-8': 29,\n",
       "             't\\xad': 36,\n",
       "             '72': 52,\n",
       "             'kh': 3,\n",
       "             'a\\xad': 50,\n",
       "             'k\\xad': 7,\n",
       "             'q.': 1,\n",
       "             '73': 50,\n",
       "             'aa': 200,\n",
       "             'o\\xad': 56,\n",
       "             'm;': 5,\n",
       "             'kp': 44,\n",
       "             'd\\xad': 16,\n",
       "             'h\\xad': 10,\n",
       "             'e;': 46,\n",
       "             'g\"': 11,\n",
       "             'hc': 22,\n",
       "             'yp': 38,\n",
       "             't!': 2,\n",
       "             '74': 78,\n",
       "             'v*': 1,\n",
       "             's\\xad': 48,\n",
       "             'z*': 1,\n",
       "             'e*': 20,\n",
       "             '--': 15,\n",
       "             'r*': 11,\n",
       "             'bg': 1,\n",
       "             'kf': 4,\n",
       "             'm&': 1,\n",
       "             '&i': 1,\n",
       "             '24': 51,\n",
       "             'i\"': 2,\n",
       "             'vh': 2,\n",
       "             ',8': 21,\n",
       "             '\"f': 8,\n",
       "             ',2': 35,\n",
       "             't^': 3,\n",
       "             '(e': 37,\n",
       "             '.g': 6,\n",
       "             '-2': 22,\n",
       "             '(c': 50,\n",
       "             'ix': 64,\n",
       "             '/i': 14,\n",
       "             '(i': 30,\n",
       "             '(g': 15,\n",
       "             't)': 16,\n",
       "             'tn': 45,\n",
       "             'ky': 28,\n",
       "             '01': 48,\n",
       "             '77': 85,\n",
       "             '(t': 25,\n",
       "             '-o': 29,\n",
       "             'n)': 6,\n",
       "             '8t': 3,\n",
       "             'r/': 13,\n",
       "             '/e': 13,\n",
       "             '-e': 63,\n",
       "             'sg': 32,\n",
       "             'g)': 9,\n",
       "             'w3': 1,\n",
       "             '32': 29,\n",
       "             'bv': 8,\n",
       "             '88': 29,\n",
       "             '89': 25,\n",
       "             'my': 51,\n",
       "             'lg': 20,\n",
       "             '(5': 5,\n",
       "             '51': 44,\n",
       "             '42': 20,\n",
       "             '41': 19,\n",
       "             ',3': 19,\n",
       "             'n/': 16,\n",
       "             '9,': 60,\n",
       "             'vl': 20,\n",
       "             'hv': 5,\n",
       "             'vd': 7,\n",
       "             'xv': 2,\n",
       "             'vt': 2,\n",
       "             '4(': 13,\n",
       "             ',4': 30,\n",
       "             '4-': 11,\n",
       "             '34': 22,\n",
       "             'c1': 2,\n",
       "             '1c': 2,\n",
       "             'c/': 15,\n",
       "             '-n': 10,\n",
       "             'gm': 20,\n",
       "             'kc': 1,\n",
       "             'o/': 6,\n",
       "             '/s': 12,\n",
       "             \"t'\": 78,\n",
       "             ',6': 26,\n",
       "             '95': 23,\n",
       "             'kg': 29,\n",
       "             'm,': 89,\n",
       "             '$3': 33,\n",
       "             'a}': 1,\n",
       "             '}o': 1,\n",
       "             'rh': 49,\n",
       "             't;': 20,\n",
       "             '\"m': 13,\n",
       "             '5)': 23,\n",
       "             '(u': 9,\n",
       "             'y)': 18,\n",
       "             'o;': 1,\n",
       "             '(p': 19,\n",
       "             'o)': 7,\n",
       "             'w-': 10,\n",
       "             '(b': 19,\n",
       "             'ya': 39,\n",
       "             '..': 115,\n",
       "             '53': 10,\n",
       "             '54': 14,\n",
       "             '04': 17,\n",
       "             'l;': 6,\n",
       "             'dh': 6,\n",
       "             '(f': 19,\n",
       "             '1s': 8,\n",
       "             '64': 47,\n",
       "             'py': 28,\n",
       "             '-7': 10,\n",
       "             'c,': 25,\n",
       "             'r\\xad': 45,\n",
       "             'b\\xad': 17,\n",
       "             '92': 30,\n",
       "             'mw': 4,\n",
       "             'i)': 11,\n",
       "             'js': 3,\n",
       "             'aq': 10,\n",
       "             '(v': 3,\n",
       "             ',e': 1,\n",
       "             'yc': 75,\n",
       "             '-g': 9,\n",
       "             '\"w': 19,\n",
       "             'tp': 21,\n",
       "             '2-': 29,\n",
       "             'i,': 20,\n",
       "             \"g'\": 15,\n",
       "             '#2': 1,\n",
       "             '09': 41,\n",
       "             '9.': 19,\n",
       "             'yd': 58,\n",
       "             'tk': 11,\n",
       "             '\"g': 14,\n",
       "             'ml': 24,\n",
       "             'l\\xad': 9,\n",
       "             'kl': 26,\n",
       "             \"'i\": 7,\n",
       "             'wp': 23,\n",
       "             'wm': 3,\n",
       "             'p)': 17,\n",
       "             '$5': 26,\n",
       "             '.4': 13,\n",
       "             'p-': 14,\n",
       "             '.t': 10,\n",
       "             'pc': 38,\n",
       "             'g\\xad': 11,\n",
       "             'r?': 4,\n",
       "             '44': 27,\n",
       "             '7%': 3,\n",
       "             \"'t\": 30,\n",
       "             '46': 42,\n",
       "             'yw': 5,\n",
       "             'tg': 8,\n",
       "             '.d': 4,\n",
       "             '\"r': 14,\n",
       "             'ih': 22,\n",
       "             'i/': 1,\n",
       "             'a;': 12,\n",
       "             '(l': 11,\n",
       "             'cg': 6,\n",
       "             '8.': 28,\n",
       "             '7/': 6,\n",
       "             '/8': 27,\n",
       "             'd_': 1,\n",
       "             '/3': 4,\n",
       "             '3u': 1,\n",
       "             \"'r\": 10,\n",
       "             'w”': 1,\n",
       "             'w\"': 4,\n",
       "             'vn': 1,\n",
       "             'mf': 6,\n",
       "             '.a': 16,\n",
       "             \"f'\": 2,\n",
       "             'f\\xad': 6,\n",
       "             'u^': 1,\n",
       "             't3': 2,\n",
       "             '3c': 1,\n",
       "             'y*': 8,\n",
       "             '-m': 20,\n",
       "             \"0'\": 3,\n",
       "             'c-': 7,\n",
       "             'cb': 31,\n",
       "             \"b'\": 2,\n",
       "             '1%': 3,\n",
       "             '-v': 6,\n",
       "             '-y': 22,\n",
       "             '0+': 1,\n",
       "             'lw': 15,\n",
       "             \"'v\": 8,\n",
       "             'y!': 3,\n",
       "             \"o'\": 21,\n",
       "             'ao': 17,\n",
       "             'a\"': 8,\n",
       "             'f\"': 1,\n",
       "             '-u': 28,\n",
       "             'pk': 1,\n",
       "             \".'\": 2,\n",
       "             'tz': 24,\n",
       "             '\")': 2,\n",
       "             ',a': 2,\n",
       "             'n$': 1,\n",
       "             '$>': 1,\n",
       "             '>e': 1,\n",
       "             'vr': 18,\n",
       "             'i-': 12,\n",
       "             'tb': 3,\n",
       "             'jm': 1,\n",
       "             \"i'\": 18,\n",
       "             \"'l\": 8,\n",
       "             '.2': 15,\n",
       "             '.b': 7,\n",
       "             '.8': 7,\n",
       "             'sn': 28,\n",
       "             '-.': 3,\n",
       "             'yz': 20,\n",
       "             '\"v': 4,\n",
       "             'l\"': 8,\n",
       "             '/u': 1,\n",
       "             'uz': 4,\n",
       "             'zz': 2,\n",
       "             'zw': 1,\n",
       "             \"h'\": 8,\n",
       "             '4)': 12,\n",
       "             'dt': 9,\n",
       "             's?': 6,\n",
       "             'm\"': 4,\n",
       "             '78': 44,\n",
       "             ':i': 1,\n",
       "             'g:': 16,\n",
       "             'w:': 4,\n",
       "             'iw': 2,\n",
       "             'r)': 12,\n",
       "             'd*': 5,\n",
       "             'lb': 13,\n",
       "             'q1': 1,\n",
       "             '1a': 3,\n",
       "             'f-': 15,\n",
       "             'v,': 8,\n",
       "             ');': 16,\n",
       "             '6;': 1,\n",
       "             's*': 24,\n",
       "             'kt': 3,\n",
       "             '.-': 8,\n",
       "             'fc': 8,\n",
       "             '.i': 7,\n",
       "             'cw': 1,\n",
       "             'v)': 1,\n",
       "             '\"y': 3,\n",
       "             'i\\xad': 8,\n",
       "             'e^': 1,\n",
       "             'u\\xad': 20,\n",
       "             '6\"': 2,\n",
       "             'a-': 23,\n",
       "             'a0': 7,\n",
       "             '0m': 2,\n",
       "             'm9': 1,\n",
       "             \"k'\": 1,\n",
       "             'qc': 2,\n",
       "             ',b': 2,\n",
       "             'f/': 3,\n",
       "             'wy': 8,\n",
       "             'y/': 13,\n",
       "             '/r': 8,\n",
       "             '^f': 1,\n",
       "             '(3': 11,\n",
       "             '(4': 6,\n",
       "             \"w'\": 3,\n",
       "             'hw': 15,\n",
       "             'dn': 26,\n",
       "             '02': 24,\n",
       "             '^a': 5,\n",
       "             ',1': 37,\n",
       "             '\"o': 7,\n",
       "             ',f': 1,\n",
       "             'cq': 8,\n",
       "             '/f': 6,\n",
       "             'j.': 34,\n",
       "             'wf': 2,\n",
       "             'cf': 4,\n",
       "             '.h': 6,\n",
       "             '\"8': 1,\n",
       "             '0\"': 1,\n",
       "             \"'.\": 2,\n",
       "             'm:': 5,\n",
       "             '/t': 8,\n",
       "             ',7': 34,\n",
       "             'yv': 6,\n",
       "             '58': 17,\n",
       "             '2n': 2,\n",
       "             'e#': 4,\n",
       "             'i1': 2,\n",
       "             '1i': 1,\n",
       "             't#': 2,\n",
       "             'r<': 1,\n",
       "             'd#': 2,\n",
       "             'y#': 1,\n",
       "             's#': 5,\n",
       "             '\"e': 17,\n",
       "             'xl': 3,\n",
       "             'o*': 1,\n",
       "             '1/': 21,\n",
       "             '/2': 10,\n",
       "             \"p'\": 13,\n",
       "             'sb': 30,\n",
       "             \"'d\": 5,\n",
       "             'n*': 9,\n",
       "             's<': 1,\n",
       "             ',t': 3,\n",
       "             'fw': 1,\n",
       "             'h)': 4,\n",
       "             'db': 16,\n",
       "             'ej': 13,\n",
       "             '\"l': 5,\n",
       "             'r\"': 8,\n",
       "             ...})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ld7b_1PMDPn"
   },
   "outputs": [],
   "source": [
    "def feature_matrix(X):\n",
    "    #input: a list of words\n",
    "    #Output: a dataframe included features, every feature is a list\n",
    "    \n",
    "    ##### Feature extracting\n",
    "    # feature 1 \n",
    "    length = []\n",
    "\n",
    "    # feature 2\n",
    "    vowels_count = []\n",
    "    consonants_count = []\n",
    "    quotients_v_l = []\n",
    "    quotients_c_l = []\n",
    "    quotients_v_c = []\n",
    "\n",
    "    # feature 3\n",
    "    nonalpha = []\n",
    "\n",
    "    # feature 4\n",
    "    digits = []\n",
    "    quotients_d_l = []\n",
    "\n",
    "    # feature 5\n",
    "    lowers = []\n",
    "    uppers = []\n",
    "    quotients_low_l = []\n",
    "    quotients_up_l = []\n",
    "    \n",
    "    #feature 6\n",
    "    consecutive_occur = []\n",
    "    quotients_cons_l = []\n",
    "    \n",
    "    #feature 7\n",
    "    quotients_la = [] # total number of vowels, consonants and digits\n",
    "    \n",
    "    #feature 8\n",
    "    consonants_secut = []\n",
    "    \n",
    "    #feature 9\n",
    "    fix_nonalpha = []\n",
    "\n",
    "    # feature bigram\n",
    "    bigr = []\n",
    "\n",
    "    #most frequent symbol\n",
    "    most_freq = []\n",
    "    \n",
    "    #non-alphabetical symbols\n",
    "    l2 = []\n",
    "    \n",
    "    for tk in X:\n",
    "        ### feature 1\n",
    "        l = len(tk)\n",
    "        length.append(l)\n",
    "\n",
    "        ### feature 2\n",
    "        tkl = tk.lower()\n",
    "        v_count = 0\n",
    "        for v in tkl:\n",
    "            if v in vowels:\n",
    "                v_count +=1\n",
    "        vowels_count.append(v_count)\n",
    "\n",
    "        c_count = 0\n",
    "        for c in tkl:\n",
    "            if c in consonants:\n",
    "                c_count +=1\n",
    "        consonants_count.append(c_count)\n",
    "\n",
    "        quotients_v_l.append(v_count/l)\n",
    "        quotients_c_l.append(c_count/l)\n",
    "        quot_v_c = safe_div(v_count,c_count)\n",
    "        quotients_v_c.append(quot_v_c)\n",
    "\n",
    "        ### feature 4\n",
    "        d_count = len([d for d in tk if d in digits])\n",
    "        digits.append(d_count)\n",
    "        quotients_d_l.append(d_count/l)\n",
    "\n",
    "        ### feature 3\n",
    "        s_count = len([s for s in tk if s not in vowels or consonants or digits])\n",
    "        nonalpha.append(s_count)\n",
    "\n",
    "        ### feature 5\n",
    "        low_count = count_low(tk)\n",
    "        lowers.append(low_count)\n",
    "        up_count = count_up(tk)\n",
    "        uppers.append(up_count)\n",
    "        quotients_low_l.append(low_count/l)\n",
    "        quotients_up_l.append(up_count/l)\n",
    "\n",
    "        ### feature 6\n",
    "        cons_occur_count = int(count_cons_occur_symbol(tk))\n",
    "        consecutive_occur.append(cons_occur_count)\n",
    "        if cons_occur_count >= 3:\n",
    "            quotients_cons_l.append(cons_occur_count/l)\n",
    "        else:\n",
    "            quotients_cons_l.append(0)\n",
    "\n",
    "        ### feature 7\n",
    "        la = v_count + c_count + d_count\n",
    "        if s_count > la:\n",
    "            quotients_la.append(1)\n",
    "        else:\n",
    "            quotients_la.append(0)\n",
    "\n",
    "        ### feature 8\n",
    "        consonance_cons_cccur_count = int(count_cons_occur_consonants(tk))\n",
    "        if consonance_cons_cccur_count >= 6:\n",
    "            consonants_secut.append(1)\n",
    "        else:\n",
    "            consonants_secut.append(0)\n",
    "\n",
    "        ### feature 9\n",
    "        tk_removed = trim_word(tk)\n",
    "        k_count = len([k for k in tk_removed if k not in vowels or consonants or digits])\n",
    "        if k_count >=3:\n",
    "            fix_nonalpha.append(1)\n",
    "        else:\n",
    "            fix_nonalpha.append(0)  \n",
    "\n",
    "        ### feature 10 bigram\n",
    "        bf = get_bigram_freq(tk, bigram_dict)\n",
    "\n",
    "        lower_tess_tokens = []\n",
    "        tkl_t = tk.lower()\n",
    "        lower_tess_tokens.append(tkl_t)\n",
    "\n",
    "        n = len(set(lower_tess_tokens))\n",
    "        big = (sum(bf)/10000)/n \n",
    "        bigr.append(big)\n",
    "\n",
    "        ### feature 11 most frequent symbol\n",
    "        i_count = Counter(tk).most_common(1)[0][1]\n",
    "        if i_count >=3:\n",
    "            most_freq.append(1)\n",
    "        else:\n",
    "            most_freq.append(0)\n",
    "\n",
    "        ### feature 12 Non-alphabetical symbols: nonalpha/total symbols\n",
    "        l1 = len([v for v in tk.lower() if v in vowels] + [c for c in tk.lower() if c in consonants])\n",
    "        l2_count = l - l1\n",
    "        quot_l2 = safe_div(l2_count,l1)\n",
    "        l2.append(quot_l2)  \n",
    "        \n",
    "    ##### construct a feature dataframe for SVM\n",
    "    df1 = pd.DataFrame({'length': length,\n",
    "                        'vowels': vowels_count,\n",
    "                        'consonants': consonants_count,\n",
    "                        'quot v/l': quotients_v_l,\n",
    "                        'quot c/l': quotients_c_l,\n",
    "                        'quot v/c': quotients_v_c,\n",
    "                        'nonalpha': nonalpha,\n",
    "                        'digits': digits,\n",
    "                        'quot d/l': quotients_d_l,\n",
    "                        'lowers': lowers,\n",
    "                        'uppers': uppers,\n",
    "                        'quot low/l': quotients_low_l,\n",
    "                        'quot up/l': quotients_up_l,\n",
    "                        'cons occur': consecutive_occur,\n",
    "                        'quot cons/l': quotients_cons_l,\n",
    "                        'quot la': quotients_la,\n",
    "                        'consonants_secut': consonants_secut,\n",
    "                        'fix_nonalpha': fix_nonalpha,\n",
    "                        'bigr': bigr,\n",
    "                        'most_freq' : most_freq,\n",
    "                        'l2': l2})\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L4qm7cN9RDqv"
   },
   "outputs": [],
   "source": [
    "#it takes about 10 mins\n",
    "X_feature_train = feature_matrix(X_train)\n",
    "X_feature_test = feature_matrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature_train.to_csv('../output/X_feature_train')\n",
    "X_feature_test.to_csv('../output/X_feature_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "VD1UsNAORDq0",
    "outputId": "34b6487b-0fba-43ae-f87b-271c4e046e5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shengweihuang/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it takes about 20 mins\n",
    "svclassifier = SVC(kernel='rbf')  \n",
    "svclassifier.fit(X_feature_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "import pickle\n",
    "filename = '../output/SVM_model.sav'\n",
    "pickle.dump(svclassifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this chunk is for load model\n",
    "import pickle\n",
    "filename = '../output/SVM_model.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSwqJ770RDq4"
   },
   "outputs": [],
   "source": [
    "#to predict\n",
    "y_pred = svclassifier.predict(X_feature_test)  \n",
    "# y_pred = svm_model.predict(X_feature_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1127
    },
    "colab_type": "code",
    "id": "XGh8N69KRDq8",
    "outputId": "f592fa21-538d-44c6-baaf-d065761ff038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tokens_tesseract  Predict_by_SVM\n",
      "0        initiative               0\n",
      "1           Charles               0\n",
      "2                 s               1\n",
      "3                '5               1\n",
      "4              fall               0\n",
      "5                en               0\n",
      "6             3111:               1\n",
      "7            repeal               0\n",
      "8            rlghts               1\n",
      "9                19               1\n",
      "10           Monday               0\n",
      "11              our               0\n",
      "12          leaders               0\n",
      "13              EMC               0\n",
      "14             Such               0\n",
      "15      Interagency               1\n",
      "16               be               0\n",
      "17         Vlolates               0\n",
      "18      preparatlon               1\n",
      "19               1n               1\n",
      "20           showed               0\n",
      "21             fees               0\n",
      "22               on               0\n",
      "23           method               0\n",
      "24             Last               0\n",
      "25               on               0\n",
      "26        emlsslons               1\n",
      "27             from               0\n",
      "28             Hlth               1\n",
      "29         attached               0\n",
      "..              ...             ...\n",
      "70            waste               0\n",
      "71               by               0\n",
      "72         concepts               1\n",
      "73              tax               0\n",
      "74              the               0\n",
      "75              and               0\n",
      "76       understand               1\n",
      "77              are               0\n",
      "78        1,090,000               1\n",
      "79                0               1\n",
      "80              and               0\n",
      "81         prop-sed               0\n",
      "82             CMA.               0\n",
      "83          hearlng               0\n",
      "84               by               0\n",
      "85              for               0\n",
      "86         conflrms               1\n",
      "87             con*               1\n",
      "88              The               0\n",
      "89                a               0\n",
      "90               1,               1\n",
      "91          strldes               1\n",
      "92      Callfornla,               1\n",
      "93     proceedlngs.               1\n",
      "94             such               0\n",
      "95              and               0\n",
      "96         Chemlcal               1\n",
      "97           event,               0\n",
      "98                e               0\n",
      "99              and               0\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_output = pd.DataFrame({'tokens_tesseract':X_test,\n",
    "                          'Predict_by_SVM': y_pred})\n",
    "print(df_output[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "LgJ-6B2tRDrC",
    "outputId": "e4512c20-ce44-4c10-e203-e21bba73e5b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16206  2142]\n",
      " [ 3484  8597]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85     18348\n",
      "           1       0.80      0.71      0.75     12081\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     30429\n",
      "   macro avg       0.81      0.80      0.80     30429\n",
      "weighted avg       0.81      0.82      0.81     30429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### evaluation\n",
    "#confustion Matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MLP performs bad\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X_feature_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18348     0]\n",
      " [12081     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75     18348\n",
      "           1       0.00      0.00      0.00     12081\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     30429\n",
      "   macro avg       0.30      0.50      0.38     30429\n",
      "weighted avg       0.36      0.60      0.45     30429\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shengweihuang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = '../output/MLP_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "\n",
    "y_pred = clf.predict(X_feature_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_feature_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17416   932]\n",
      " [ 2156  9925]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     18348\n",
      "           1       0.91      0.82      0.87     12081\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     30429\n",
      "   macro avg       0.90      0.89      0.89     30429\n",
      "weighted avg       0.90      0.90      0.90     30429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = '../output/KNN_model.sav'\n",
    "pickle.dump(neigh, open(filename, 'wb'))\n",
    "\n",
    "y_pred = neigh.predict(X_feature_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(n_estimators=10,min_samples_split=2, random_state=0)\n",
    "RF = RF.fit(X_feature_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17416   932]\n",
      " [ 2156  9925]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     18348\n",
      "           1       0.91      0.82      0.87     12081\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     30429\n",
      "   macro avg       0.90      0.89      0.89     30429\n",
      "weighted avg       0.90      0.90      0.90     30429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = '../output/RF_model.sav'\n",
    "pickle.dump(neigh, open(filename, 'wb'))\n",
    "\n",
    "y_pred = neigh.predict(X_feature_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7ezVSAnaity"
   },
   "source": [
    "## Error correction(I didn't run this part--Xishi Chen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2CktPwLtalAr"
   },
   "source": [
    "Given the detected word error, in order to find the best correction, we need to generating the candidate corrections: a dictionary or a database of legal n-grams to locate one or more potential correction terms. Then we need invoke some lexical-similarity measure between the misspelled string and the candidates or a probabilistic estimate of the likelihood of the correction to rank order the candidates. Here, we implement the positional binary digram method in the first reference paper. (https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1672564}{positional binary digram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-VEfK86-1Dd5"
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fn7sOOYDapFz"
   },
   "outputs": [],
   "source": [
    "def keep_alphabet(tokens):\n",
    "  # only retain alphabet\n",
    "  out = []\n",
    "  for l in tokens:\n",
    "      l = l.lower()\n",
    "      if l in set('abcdefghijklmnopqrstuvwxyz '):\n",
    "          out.append(l)\n",
    "  return ''.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOWpBGeSeAzz"
   },
   "outputs": [],
   "source": [
    "# Replace a postion of a string\n",
    "def replace_str_index(text,index=0,replacement=''):\n",
    "    return '%s%s%s'%(text[:index],replacement,text[index+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UBwd4B3oh6LL"
   },
   "outputs": [],
   "source": [
    "# Define the main correction function\n",
    "def correction(word, digrams):\n",
    "  detect = 0\n",
    "  beta = []\n",
    "  # Find the error positions\n",
    "  for each in digrams:\n",
    "    matrix = digrams[each]\n",
    "    if matrix[string.ascii_lowercase.index(word[each[0]])][string.ascii_lowercase.index(word[each[1]])] == 0:\n",
    "      detect += 1\n",
    "      beta_each = set(each)\n",
    "      if detect == 1:\n",
    "        beta = beta_each\n",
    "      else:\n",
    "        beta = beta.intersection(beta_each)\n",
    "  # print(beta)\n",
    "  # Consider when there is one or two elements in beta\n",
    "  if len(beta) in [1,2]:\n",
    "    choices = 0\n",
    "    v_dict = {}\n",
    "    for i in beta:\n",
    "      v_list = []\n",
    "      position = i\n",
    "      for j in range(len(word)):\n",
    "        alpha_j = string.ascii_lowercase.index(word[j])\n",
    "        if j < position:\n",
    "          vector_j = digrams[(j, position)][alpha_j]\n",
    "          v_list.append(vector_j)\n",
    "        elif j > position:\n",
    "          vector_j = [item[alpha_j] for item in digrams[(position, j)]]\n",
    "          v_list.append(vector_j)\n",
    "      v = v_list[0]\n",
    "      for each in v_list:\n",
    "        v = [a and b for a, b in zip(v, each)]\n",
    "      if sum(v) == 1:\n",
    "        choices += 1\n",
    "        v_dict[i] = v\n",
    "    if choices == 1:\n",
    "      for key in v_dict:\n",
    "        position_chosen = key\n",
    "      word = replace_str_index(word, position_chosen, string.ascii_lowercase[v_dict[position_chosen].index(1)])\n",
    "  return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vr1Bsyh1cPUL"
   },
   "outputs": [],
   "source": [
    "for i in range(len(ground_train)):\n",
    "  ground_train[i] = keep_alphabet(ground_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KztP5VHZcN2J"
   },
   "outputs": [],
   "source": [
    "# Create dictionary of digrams\n",
    "token_by_len = collections.defaultdict(list)\n",
    "digrams_by_len = collections.defaultdict(dict)\n",
    "for w in ground_train:\n",
    "  token_by_len[len(w)].append(w)\n",
    "  \n",
    "#print('Number of words of diffenrent length:')\n",
    "#for key, value in token_by_len.items() :\n",
    "#    print (key, len(value))\n",
    "\n",
    "for length in token_by_len:\n",
    "  for i, j in itertools.combinations(range(length), 2):\n",
    "    key = (i, j)\n",
    "    matrix = [[0] * 26 for _ in range(26)]\n",
    "    for words in token_by_len[length]:\n",
    "      matrix[string.ascii_lowercase.index(words[i])][string.ascii_lowercase.index(words[j])] = 1\n",
    "    digrams_by_len[length][key] = matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KBWvfZZbVQCd",
    "outputId": "37ca3d07-b0b8-43e7-b024-43ed70a60e85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "# Number of 1 in digrams with given length\n",
    "ae = 0\n",
    "for each in digrams_by_len[10][(0,1)]:\n",
    "  ae += sum(each)\n",
    "print(ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEmgfeS4KP5R"
   },
   "outputs": [],
   "source": [
    "# Clean the words\n",
    "corrected_test = X_test.copy()\n",
    "for i in range(len(corrected_test)):\n",
    "  corrected_test[i] = keep_alphabet(corrected_test[i])\n",
    "for i in range(len(ground_test)):\n",
    "  ground_test[i] = keep_alphabet(ground_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7TSJth-EgTOb"
   },
   "outputs": [],
   "source": [
    "# Make correction\n",
    "for i in range(len(y_pred)):\n",
    "  if y_pred[i] == 1:\n",
    "    word_length = len(corrected_test[i])\n",
    "    if word_length > 1:\n",
    "      digrams_i = digrams_by_len[word_length]\n",
    "      corrected_test[i] = correction(corrected_test[i], digrams_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "towmW8Vkuj3-"
   },
   "outputs": [],
   "source": [
    "y_corrected = []\n",
    "for gt, ct in zip(ground_test, corrected_test):\n",
    "        if gt == ct:\n",
    "            y_corrected.append(0)   # 0 indicates correct\n",
    "        else:\n",
    "            y_corrected.append(1)   # 1 indicates error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "P2uE-TeO7bQX",
    "outputId": "57b2e4a2-e157-4aeb-e8ec-52df581fcb90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['initiative', 'charles', 's', '', 'fall', 'en', '', 'repeal', 'rlghts', '', 'monday', 'our', 'leaders', 'emc', 'such', 'interagency', 'be', 'vlolates', 'preparatlon', 'n', 'showed', 'fees', 'on', 'method', 'last', 'on', 'emlsslons', 'from', 'hlth', 'attached']\n",
      "['was', 'charles', 'foodrelated', 'board', 'fall', 'enacted', 'bills', 'repeal', 'rights', '', 'monday', 'our', 'leaders', 'emc', 'such', 'interagency', 'be', 'violates', 'preparation', 'in', 'showed', 'fees', 'on', 'method', 'last', 'on', 'emissions', 'a', 'with', 'attached']\n",
      "['initiative', 'Charles', 's', \"'5\", 'fall', 'en', '3111:', 'repeal', 'rlghts', '19', 'Monday', 'our', 'leaders', 'EMC', 'Such', 'Interagency', 'be', 'Vlolates', 'preparatlon', '1n', 'showed', 'fees', 'on', 'method', 'Last', 'on', 'emlsslons', 'from', 'Hlth', 'attached']\n"
     ]
    }
   ],
   "source": [
    "# Compare the results\n",
    "print(corrected_test[:30])\n",
    "print(ground_test[:30])\n",
    "print(X_test[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "RathHlusCCmv",
    "outputId": "0357315b-8faa-4676-abf4-1093d94898c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12081\n",
      "10357\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_test))\n",
    "print(sum(y_corrected))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZVSjkKFiAwdQ"
   },
   "source": [
    "## Performance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o8QLnVn18-k7"
   },
   "outputs": [],
   "source": [
    "# Create corresponding lists of characters\n",
    "corrected_char = []\n",
    "for each in corrected_test:\n",
    "  corrected_char += each\n",
    "corrected_char\n",
    "\n",
    "ground_char = []\n",
    "for each in ground_test:\n",
    "  ground_char += each\n",
    "\n",
    "tess_char = [] \n",
    "tess_test = X_test.copy()\n",
    "for i in range(len(tess_test)):\n",
    "  tess_test[i] = keep_alphabet(tess_test[i])\n",
    "for each in tess_test:\n",
    "  tess_char += each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RN0kdSp_RoYM"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7swhDLPT-EZK"
   },
   "outputs": [],
   "source": [
    "# Count the number of characters\n",
    "ground_count = []\n",
    "corrected_count = []\n",
    "tess_count = []\n",
    "for each in string.ascii_lowercase:\n",
    "  ground_count.append(ground_char.count(each))\n",
    "  corrected_count.append(corrected_char.count(each))\n",
    "  tess_count.append(tess_char.count(each))\n",
    "ground_corrected_min = np.minimum(ground_count, corrected_count)\n",
    "ground_tess_min = np.minimum(ground_count, tess_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "iH01NQqpAowo",
    "outputId": "b2436256-1bf0-447e-b71d-28f14b99f950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Tesseract  Tesseract_with_postprocessing\n",
      "word_wise_recall           0.602977                       0.659634\n",
      "word_wise_precision        0.602977                       0.659634\n",
      "character_wise_recall      0.912228                       0.917197\n",
      "character_wise_precision   0.946315                       0.951469\n"
     ]
    }
   ],
   "source": [
    "# Make the evaluation table\n",
    "word_recall_tess = 1 - sum(y_test)/len(ground_test)\n",
    "word_recall_corrected = 1 - sum(y_corrected)/len(ground_test)\n",
    "word_precision_tess = 1 - sum(y_test)/len(X_test)\n",
    "word_precision_corrected = 1 - sum(y_corrected)/len(X_test)\n",
    "char_recall_tess = sum(ground_tess_min)/sum(ground_count)\n",
    "char_precision_tess = sum(ground_tess_min)/sum(tess_count)\n",
    "char_recall_corrected = sum(ground_corrected_min)/sum(ground_count)\n",
    "char_precision_corrected = sum(ground_corrected_min)/sum(corrected_count)\n",
    "\n",
    "d = {'Tesseract': [word_recall_tess, word_precision_tess, char_recall_tess, char_precision_tess], \n",
    "     'Tesseract_with_postprocessing': [word_recall_corrected, word_precision_corrected \n",
    "                                       ,char_recall_corrected, char_precision_corrected]}\n",
    "OCR_performance_table = pd.DataFrame(data=d)\n",
    "OCR_performance_table.rename(index={0: 'word_wise_recall', 1:'word_wise_precision', \n",
    "                                    2:'character_wise_recall', 3:'character_wise_precision'}, inplace=True)\n",
    "print(OCR_performance_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kHvcr4LMA0VQ"
   },
   "source": [
    "The word-wise recall after postprocessing is 0.6595, significantly better than original Tesseract text. Word-wise precision is the same as recall because of our preprocessing. The character-wise recall and precision are slightly improved to 0.9176 and 0.951."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project4_Detection_v4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
